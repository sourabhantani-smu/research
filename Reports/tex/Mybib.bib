@article{alon97,
  author  = {N. Alon and N. Kahale},
  title   = {A spectral technique for coloring random 3-colorable graphs},
  journal = {SIAM J. Comput.},
  year    = 1997,
  volume  = 26,
  pages   = {1733-1748}
}
@article{alon98,
  author  = {N. Alon},
  title   = {Spectral Techniques in Graph Algorithms},
  journal = {Lecture Notes in Computer Science},
  year    = 1998,
  volume  = 1380,
  pages   = {206-215},
  annote  = {(Invited Paper)}
}
@article{bach-06b,
  author  = {Bach, F. R. and Michael I. Jordan},
  title   = {Learning Spectral Clustering, With Application To Speech Separation},
  journal = {J. Mach. Learn. Res.},
  volume  = 7,
  year    = 2006,
  pages   = {1963--2001}
}

@inproceedings{pmlr-v37-boutsidis15,
  title     = {Spectral Clustering via the Power Method - Provably},
  author    = {Boutsidis, Christos and Kambadur, Prabhanjan and Gittens, Alex},
  booktitle = {Proceedings of the 32nd International Conference on Machine Learning},
  pages     = {40--48},
  year      = {2015},
  editor    = {Bach, Francis and Blei, David},
  volume    = {37},
  series    = {Proceedings of Machine Learning Research},
  address   = {Lille, France},
  month     = {07--09 Jul},
  publisher = {PMLR},
  pdf       = {http://proceedings.mlr.press/v37/boutsidis15.pdf},
  url       = { http://proceedings.mlr.press/v37/boutsidis15.html },
  abstract  = {Spectral clustering is one of the most important algorithms in data mining and machine intelligence; however, its computational complexity limits its application to truly large scale data analysis. The computational bottleneck in spectral clustering is computing a few of the top eigenvectors of the (normalized) Laplacian matrix corresponding to the graph representing the data to be clustered. One way to speed up the computation of these eigenvectors is to use the “power method” from the numerical linear algebra literature. Although the power method has been empirically used to speed up spectral clustering, the theory behind this approach, to the best of our knowledge, remains unexplored. This paper provides the first such rigorous theoretical justification, arguing that a small number of power iterations suffices to obtain near-optimal partitionings using the approximate eigenvectors. Specifically, we prove that solving the k-means clustering problem on the approximate eigenvectors obtained via the power method gives an additive-error approximation to solving the k-means problem on the optimal eigenvectors.}
}
@book{bapat-graph-2014,
  title     = {{Graphs and Matrices}},
  author    = {Ravindra B. Bapat},
  publisher = {Springer-Verlag},
  year      = {2014},
  series    = {Universitext},
  edition   = {2nd}
}



@article{bengio-04,
  author   = {Bengio, Y. and Delalleau, O. and Le Roux, N. and
                  Paiement, J. and Vincent, P. and Ouimet, M.},
  title    = {Learning Eigenfunctions Links Spectral Embedding
                  and Kernel {PCA}},
  journal  = {Neural Computation},
  volume   = 16,
  number   = 10,
  pages    = {2197-2219},
  year     = 2004,
  abstract = {In this letter, we show a direct relation between
                  spectral embedding methods and kernel principal
                  components analysis and how both are special cases
                  of a more general learning problem: learning the
                  principal eigenfunctions of an operator defined from
                  a kernel and the unknown data-generating
                  density. Whereas spectral embedding methods provided
                  only coordinates for the training points, the
                  analysis justifies a simple extension to
                  out-of-sample examples (the Nystrom formula) for
                  multidimensional scaling (MDS), spectral clustering,
                  Laplacian eigenmaps, locally linear embedding (LLE),
                  and Isomap. The analysis provides, for all such
                  spectral embedding methods, the definition of a loss
                  function, whose empirical average is minimized by
                  the traditional algorithms. The asymptotic expected
                  value of that loss defines a generalization
                  performance and clarifies what these algorithms are
                  trying to learn. Experiments with LLE, Isomap,
                  spectral clustering, and MDS show that this
                  out-of-sample embedding formula generalizes well,
                  with a level of error comparable to the effect of
                  small perturbations of the training set on the
                  embedding. }
}

@incollection{bengio-lecun-scalingAI-07,
  author    = {Bengio, Yoshua and LeCun, Yann},
  editor    = {Bottou, L\'eon and Chapelle, Olivier and DeCoste, D. and Weston, J.},
  title     = {Scaling Learning Algorithms towards {AI}},
  booktitle = {Large-Scale Kernel Machines},
  pages     = {321-359},
  year      = {2007},
  publisher = {MIT Press}
}

@book{brualdi-2006,
  title     = {Combinatorial matrix classes},
  author    = {Richard A. Brualdi},
  publisher = {Cambridge University Press},
  year      = 2006,
  series    = {Encyclopedia of Mathematics and its Applications, vol. 108}
}
@book{brualdi-cvet-2008,
  title     = {{A Combinatorial Approach to Matrix Theory and Its Applications}},
  author    = {Richard A. Brualdi and Dragos Cvetkovi\'c},
  publisher = {Chapman and Hall/CRC Press},
  year      = 2008,
  series    = {Discrete Mathematics and Its Applications}
}
@misc{bruna-spectral-graph-13,
  title        = {Spectral Networks and Locally Connected Networks on Graphs},
  author       = {Joan Bruna and Wojciech Zaremba and Arthur Szlam and Yann LeCun},
  year         = {arXiv:1312.6203, 2013},
  primaryclass = {cs.LG}
}

@article{candes-cs-06,
  author  = {Cand\`{e}s, E.J. and Romberg, J. and Tao, T.},
  title   = {Robust uncertainty principles: exact signal
                  reconstruction from highly incomplete frequency
                  information},
  journal = {IEEE Transactions on Information Theory},
  number  = 2,
  pages   = {489--509},
  volume  = 52,
  year    = 2006
}

@article{candes-rech-09,
  author  = {Cand\`{e}s, E. J. and Recht, B.},
  title   = {Exact Matrix Completion via Convex Optimization},
  journal = {Foundations of Computational Mathematics},
  pages   = {717-772},
  volume  = 9,
  issue   = 6,
  year    = 2009
}

@article{candes-RPCA-11,
  title   = {Robust Principal Component Analysis?},
  author  = {Cand\`{e}s, E. J. and Li, X. and Ma, Y. and J. Wright},
  journal = {J. of ACM},
  number  = 3,
  pages   = {11:1-37},
  volume  = 58,
  year    = 2011
}

@article{candes-tao-05,
  title   = {{Decoding by Linear Programming}},
  author  = {Cand\`es, E.J. and Tao, T.},
  journal = {IEEE Transactions on Information Theory},
  number  = 12,
  pages   = {4203--4215},
  volume  = 51,
  year    = 2005
}

@article{candes-tao-06U,
  title   = {{Near-Optimal Signal Recovery From Random
                  Projections: Universal Encoding Strategies?}},
  author  = {Cand\`{e}s, E. J. and Tao, T.},
  journal = {IEEE Transactions on Information Theory},
  number  = 12,
  pages   = {5406--5425},
  volume  = 52,
  year    = 2006
}
@article{candes-tao-10,
  author  = {Cand\`{e}s, E. J. and Tao, T.},
  title   = {The power of convex relaxation: near-optimal matrix
                  completion},
  journal = {IEEE Trans. Inf. Theor.},
  volume  = 56,
  issue   = 5,
  year    = 2010,
  pages   = {2053--2080}
}

@book{cevt-2010,
  title     = {{An Introduction to the Theory of Graph Spectra}},
  author    = {Dragos M. Cvetkovi\'c and Peter Rowlinson and Slobodan Simi\'c},
  publisher = {Cambridge University Press},
  year      = 2010,
  series    = {London Mathematical Society -- Student Texts 75}
}
@article{ChDoSa01,
  author  = {Chen, S.S. and Donoho, D.L. and Saunders, M.A.},
  title   = {Atomic decomposition by basis pursuit},
  journal = {SIAM review},
  number  = 1,
  pages   = {129--159},
  volume  = 43,
  year    = 2001
}

@article{cheb-rat-05,
  author  = {J. P. Boyd},
  title   = {A {Chebyshev}/rational {Chebyshev} spectral method
                  for the {Helmholtz} equation in a sector on the
                  surface of a sphere: defeating corner singularities},
  journal = JCP,
  year    = 2005,
  volume  = 206,
  number  = 1,
  pages   = {302-310}
}

@article{Chen-deep-comm-15,
  author  = {P.Y. Chen and A. O. Hero},
  title   = {Deep Community Detection},
  journal = {IEEE Transactions on Signal Processing},
  volume  = 63,
  number  = 21,
  pages   = {5706-5719},
  year    = 2015
}


@article{Chen-incremental-eig-Laplacian-18,
  title   = {Incremental eigenpair computation for graph
                  {Laplacian} matrices: theory and applications},
  author  = {Chen, Pin-Yu and Zhang, Baichuan and Hasan, Mohammad Al},
  journal = {Social Network Analysis and Mining},
  year    = 2017,
  volume  = 8,
  number  = 1,
  pages   = 4,
  doi     = {https://doi.org/10.1007/s13278-017-0481-y}
}

@misc{cluster-art-sci-12,
  title     = {Clustering: Science or Art?},
  author    = {Ulrike von Luxburg and Robert C. Williamson and Isabelle Guyon},
  booktitle = {Proceedings of ICML Workshop on Unsupervised and Transfer Learning},
  year      = 2012,
  pages     = {65--79},
  publisher = {PMLR},
  url       = {http://proceedings.mlr.press/v27/luxburg12a.html}
}

@incollection{cnn-fast-local-spectral-filt-16,
  title     = {Convolutional Neural Networks on Graphs with Fast Localized Spectral Filtering},
  author    = {Defferrard, Micha\"{e}l and Bresson, Xavier and Vandergheynst, Pierre},
  booktitle = {Advances in Neural Information Processing Systems 29},
  pages     = {3837--3845},
  year      = 2016,
  publisher = {Curran Associates, Inc.}
}

@article{cnn-low-rank-filter-15,
  author  = {Yani Ioannou and Duncan P. Robertson and Jamie
                  Shotton and Roberto Cipolla and Antonio Criminisi},
  title   = {Training CNNs with Low-Rank Filters for Efficient
                  Image Classification},
  journal = {CoRR},
  volume  = {abs/1511.06744},
  year    = 2015,
  url     = {http://arxiv.org/abs/1511.06744}
}


@article{CNN-via-PCA-20,
  author  = {I. Garg and P. Panda and K. Roy},
  title   = {A Low Effort Approach to Structured {CNN} Design Using {PCA}},
  pages   = {1347-1360},
  journal = {IEEE Access},
  volume  = 8,
  year    = 2020
}

@inproceedings{ding-he-04,
  author    = {Ding, C. and He, X.},
  title     = {K-means clustering via principal component analysis},
  booktitle = {Proceedings of the 21st international conference on
                  Machine learning},
  series    = {ICML '04},
  year      = 2004,
  location  = {Banff, Alberta, Canada},
  pages     = {225--232},
  publisher = {ACM}
}
@misc{Ding-He-NNMF-spect-05,
  title     = {On the Equivalence of Nonnegative Matrix Factorization and Spectral Clustering},
  author    = {Ding, Chris. and He, Xiaofeng. and Simon, Horst D.},
  journal   = {Proceedings of the 2005 SIAM International Conference on Data Mining},
  year      = {2005},
  pages     = {606-610},
  publisher = {Society for Industrial and Applied Mathematics},
  doi       = {https://doi.org/10.1137/1.9781611972757.70}
}


@article{ding:256,
  author  = {C. H. Q. Ding and H. Zha and X. He and P. Husbands and H. D. Simon},
  title   = {Link Analysis: Hubs and Authorities on the World Wide Web},
  year    = 2004,
  journal = SIREV,
  volume  = 46,
  number  = 2,
  pages   = {256-268}
}
@article{DR-dual-06,
  title     = {{A duality view of spectral methods for
                  dimensionality reduction}},
  address   = {New York, USA},
  author    = {Xiao, L. and Sun, J. and Boyd, S.},
  journal   = {Proceedings of the 23rd international conference on
                  Machine learning - ICML '06},
  pages     = {1041--1048},
  publisher = {ACM Press},
  year      = 2006
}

@article{dris97,
  author  = {T. A. Driscoll},
  title   = {Eigenmodes of Isospectral Drums},
  journal = {SIAM Review},
  year    = 1997,
  volume  = 39,
  pages   = {1-17}
}
@book{eigen-graph-1997,
  title     = {Eigenspaces of graphs},
  author    = {Dragos Cvetkovi\'c and Peter Rowlinson and Slobodan Simi\'c},
  publisher = {Cambridge University Press},
  year      = 1997,
  series    = {Encyclopedia of Mathematics and its Applications 66}
}


@article{fang2008b,
  author    = {Fang, H.-R. and Saad, Y.},
  title     = {Farthest Centroids Divisive Clustering},
  journal   = {2008 Seventh International Conference on Machine
                  Learning and Applications},
  keywords  = {graph partitioning,k-means algorithm,lanczos
                  method,spectral bisection,unsupervised clustering},
  pages     = {232--238},
  publisher = {IEEE},
  year      = 2008
}
@article{fast-svt-13,
  author  = {Cai, J.F. and Osher, S.},
  journal = {Methods and Applications of Analysis},
  number  = 4,
  pages   = {335--352},
  title   = {{Fast singular value thresholding without singular value decomposition}},
  volume  = 20,
  year    = 2013
}


@misc{GCNN-PCA-20,
  title         = {Connecting Graph Convolutional Networks and Graph-Regularized PCA},
  author        = {Lingxiao Zhao and Leman Akoglu},
  year          = 2020,
  eprint        = {2006.12294},
  archiveprefix = {arXiv},
  primaryclass  = {cs.LG}
}
@misc{GCNN-simplify-19,
  title         = {Simplifying Graph Convolutional Networks},
  author        = {Felix Wu and Tianyi Zhang and Amauri Holanda de Souza Jr. and Christopher Fifty and
                  Tao Yu and Kilian Q. Weinberger},
  year          = 2019,
  eprint        = {1902.07153},
  archiveprefix = {arXiv},
  primaryclass  = {cs.LG}
}

@article{gene:2018,
  author  = {G. {Cheung} and E. {Magli} and Y. {Tanaka} and M. K. {Ng}},
  journal = {Proceedings of the IEEE},
  title   = {Graph Spectral Image Processing},
  year    = {2018},
  volume  = {106},
  number  = {5},
  pages   = {907-930},
  doi     = {10.1109/JPROC.2018.2799702}
}
@misc{GNN-lanczos-15,
  title        = {Accelerated filtering on graphs using Lanczos method},
  author       = {Ana Susnjara and Nathanael Perraudin and Daniel Kressner and Pierre Vandergheynst},
  year         = {arXiv:1509.04537, 2015},
  primaryclass = {math.NA}
}



@article{GNN-pagerank-20,
  title     = {Scaling Graph Neural Networks with Approximate PageRank},
  url       = {http://dx.doi.org/10.1145/3394486.3403296},
  journal   = {Proc. 26th ACM SIGKDD International Conference on Knowledge Discovery \& Data
                  Mining},
  publisher = {ACM},
  author    = {Bojchevski, A. and Klicpera, J. and Perozzi, B. and Kapoor, A. and
                  Blais, M. and R\'ozemberczki, B. and Lukasik, M. and G\"unnemann, S.},
  year      = 2020
}
@article{gol_kah65,
  author  = {G. H. Golub and W. Kahan},
  title   = {Calculating the singular values and pseudo-inverse
                  of a matrix},
  journal = SINUM,
  year    = 1965,
  volume  = 2,
  pages   = {205-224}
}
@misc{gong2020geometrically,
  title         = {Geometrically Principled Connections in Graph Neural Networks},
  author        = {Shunwang Gong and Mehdi Bahri and Michael M. Bronstein and Stefanos Zafeiriou},
  year          = 2020,
  eprint        = {2004.02658},
  archiveprefix = {arXiv},
  primaryclass  = {cs.CV}
}

@book{govl:13,
  author    = {G. H. Golub and C. F. Van Loan},
  title     = {Matrix Computations},
  publisher = {Johns Hopkins University Press},
  year      = 2013,
  address   = {Baltimore, MD},
  edition   = {4th}
}

@book{govl:96,
  author    = {G. H. Golub and C. F. Van Loan},
  title     = {Matrix Computations},
  publisher = {Johns Hopkins University Press},
  year      = 1996,
  address   = {Baltimore, MD},
  edition   = {3rd}
}

@article{graph-embed-DR-07,
  title   = {Graph Embedding and Extensions: A General Framework for Dimensionality Reduction},
  author  = {S. Yan and D. Xu and B. Zhang and H. Zhang and Q. Yang and S. Lin},
  journal = {IEEE Transactions on Pattern Analysis and Machine Intelligence},
  year    = {2007},
  volume  = {29},
  number  = {1},
  pages   = {40--51},
  doi     = {https://doi.org/10.1109/TPAMI.2007.250598}
}

@book{graph-spectral-book,
  author    = {F. R. K. Chung},
  title     = {Spectral Graph Theory},
  publisher = {American Mathematical Society},
  year      = 1997,
  number    = 92,
  series    = {CBMS Regional Conference Series in Mathematics}
} 

@article{HKwon-NMNasrabadi-06,
  title   = {Kernel Matched Subspace Detectors for Hyperspectral Target Detection},
  author  = {H. Kwon and N. M. Nasrabadi},
  journal = {IEEE Transactions on Pattern Analysis \& Machine Intelligence},
  year    = {2006},
  volume  = {28},
  number  = {02},
  pages   = {178--194},
  url     = {http://doi.ieeecomputersociety.org/10.1109/TPAMI.2006.39}
}

@book{householder-75,
  author    = {A.S. Householder},
  title     = {The Theory of Matrices in Numerical Analysis},
  publisher = {Dover},
  year      = 1975,
  address   = {New York}
}

@article{incremental-spectral-10,
  title   = {Incremental spectral clustering by efficiently
                  updating the eigen-system},
  author  = {H. Ning and W. Xu and Y. Chi and Y. Gong and T. S. Huang},
  journal = {Pattern Recognition},
  volume  = 43,
  number  = 1,
  pages   = {113 - 127},
  year    = 2010,
  doi     = {https://doi.org/10.1016/j.patcog.2009.06.001}
}

@article{Influence-maximization-15,
  title    = {Influence maximization in complex networks through optimal percolation},
  author   = {Morone, Flaviano and Makse, Hernan A.},
  journal  = {Nature},
  year     = {2015},
  volume   = {524},
  number   = {7563},
  pages    = {65--68},
  doi      = {https://doi.org/10.1038/nature14604},
  abstract = {A rigorous method to determine the most influential superspreaders in complex networks is presented—involving the mapping of the problem onto optimal percolation along with a scalable algorithm for big-data social networks—showing, unexpectedly, that many weak nodes can be powerful influencers.}
}

@inproceedings{kernel-k-means-04,
  author    = {Dhillon, Inderjit S. and Guan, Yuqiang and Kulis, Brian},
  title     = {{Kernel K-Means: Spectral Clustering and Normalized Cuts}},
  year      = 2004,
  doi       = {https://doi.org/10.1145/1014052.1014118},
  booktitle = {Proc. Tenth ACM SIGKDD International Conference on Knowledge Discovery and Data Mining},
  pages     = {551--556},
  numpages  = 6,
  keywords  = {kernel k-means, graph partitioning, spectral clustering},
  series    = {KDD'04}
}
@inproceedings{kipfsemi-gCN-17,
  title     = {Semi-Supervised Classification with Graph Convolutional Networks},
  author    = {Kipf, Thomas N. and Welling, Max},
  booktitle = {International Conference on Learning Representations (ICLR)},
  year      = {2017}
}

@article{L1-LS-07,
  title   = {An interior-point method for large-scale
                  $\ell_1$-regularized least squares},
  author  = {Kim, S.J. and Koh, K. and Lustig, M. and Boyd,
                  S. and Gorinevsky, D.},
  journal = {IEEE Journal of Selected Topics in Signal
                  Processing},
  number  = 4,
  pages   = {606--617},
  volume  = 1,
  year    = 2007
}

@article{lanczos-svd,
  author  = {J. Chen and Y. Saad},
  title   = {Lanczos Vectors versus Singular Vectors for
                  Effective Dimension Reduction},
  journal = {IEEE Transactions on Knowledge and Data Engineering},
  year    = 2009,
  volume  = 21,
  number  = 8,
  pages   = {1091--1103}
}

@article{lapface-eigenmap03,
  author  = {M. Belkin and P. Niyogi},
  title   = {Laplacian Eigenmaps for Dimensionality Reduction and
                  Data Representation},
  journal = {Neural Computation},
  year    = 2003,
  volume  = 15,
  pages   = {1373-1396}
}

@article{lapface05,
  author  = {X. He and S. Yan and Y. Hu and P. Niyogi and
                  H. Zhang},
  title   = {Face recognition using {L}aplacianfaces},
  journal = ITPAMI,
  year    = 2005,
  volume  = 27,
  number  = 3,
  pages   = {328-340}
}
@article{laplacian-manifold08,
  author  = {M. Belkin and P. Niyogi},
  title   = {Towards a Theoretical Foundation for {Laplacian}-based Manifold Methods},
  journal = {Journal of Computer and System Sciences},
  year    = 2008,
  volume  = 74,
  number  = 8,
  pages   = {1289-1308}
}

@book{large-kernel-2007,
  title     = {Large-Scale Kernel Machines},
  editor    = {L\'eon Bottou and Olivier Chapelle and Dennis DeCoste and Jason Weston},
  publisher = {The MIT Press},
  year      = {2007},
  series    = {Neural Information Processing series}
}

@inproceedings{liao-lanczosnet-19,
  title     = {LanczosNet: Multi-Scale Deep Graph Convolutional Networks},
  author    = {Liao, Renjie and Zhao, Zhizhen and Urtasun, Raquel and Zemel, Richard},
  booktitle = {International Conference on Learning Representations (ICLR)},
  year      = {2019}
}

@article{Lu2015AcceleratedAF,
  title   = {Accelerated algorithms for EigenValue Decomposition with application to spectral clustering},
  author  = {Songtao Lu and Zhengdao Wang},
  journal = {2015 49th Asilomar Conference on Signals, Systems and Computers},
  year    = {2015},
  pages   = {355-359}
}

@book{lutkepohl:97,
  author    = {Helmut L\"utkepohl},
  title     = {Handbook of Matrices},
  publisher = {Wiley},
  edition   = {4th}
}

@article{Luxburg2007,
  author   = {Luxburg, U.},
  title    = {A tutorial on spectral clustering},
  journal  = {Statistics and Computing},
  number   = 4,
  pages    = {395--416},
  volume   = 17,
  year     = 2007,
  keywords = {graph laplacian,spectral clustering}
}

@article{Malik-DL-17,
  author     = {Malik, Jitendra},
  title      = {Technical Perspective: What Led Computer Vision to Deep Learning?},
  journal    = {Commun. ACM},
  issue_date = {June 2017},
  volume     = {60},
  number     = {6},
  year       = {2017},
  issn       = {0001-0782},
  pages      = {82--83},
  numpages   = {2},
  url        = {http://doi.acm.org/10.1145/3065384}
}

@article{multiway-QR-cluster-18,
  title   = {Simple, direct and efficient multi-way spectral clustering},
  author  = {Damle, Anil and Minden, Victor and Ying, Lexing},
  journal = {Information and Inference: A Journal of the IMA},
  year    = 2018,
  volume  = 8,
  number  = 1,
  pages   = {181--203},
  doi     = {https://doi.org/10.1093/imaiai/iay008}
} 

@article{ng-jordan-01,
  title   = {On spectral clustering: {A}nalysis and an algorithm},
  journal = {Proc. NIPS},
  author = {Ng, Andrew Y. and Jordan, Michael I. and Weiss, Yair},
  year = {2001},
  publisher = {MIT Press},
  address = {Cambridge, MA, USA},
  booktitle = {Proceedings of the 14th International Conference on Neural Information Processing Systems: Natural and Synthetic},
  pages = {849-856},
  numpages = {8},
  location = {Vancouver, British Columbia, Canada},
  series = {NIPS'01}
  }

@book{NNM-book-09,
  author    = {R. B. Bapat and T.E.S. Raghavan},
  title     = {Nonnegative Matrices and Applications},
  publisher = {Cambridge University Press},
  year      = 2009
}
@book{NNM-book-87,
  author    = {A. Berman and R. J. Plemmons},
  title     = {{Nonnegative Matrices in the Mathematical Sciences}},
  publisher = {SIAM Press},
  year      = 1987
}

@article{noisy-complete-10,
  title   = {Matrix Completion With Noise},
  author  = {Cand\`{e}s, E. J. and Plan, Y.},
  journal = {Proceedings of the IEEE},
  number  = 6,
  pages   = {925--936},
  volume  = 98,
  year    = 2010
}

@article{non-backtrack-15,
  author  = {C. Bordenave, M. Lelarge and L. Massoulie},
  title   = {Non-backtracking Spectrum of Random Graphs: Community Detection and Non-regular Ramanujan
                  Graphs},
  journal = {2015 IEEE 56th Annual Symposium on Foundations of Computer Science},
  pages   = {1347-1357},
  year    = 2015
}

@book{nonnegative-tensor-book,
  title     = {{Nonnegative Matrix and Tensor Factorizations: Applications to Exploratory Multi-way Data
                  Analysis and Blind Source Separation}},
  author    = {Andrzej Cichocki and Rafal Zdunek and Anh Huy Phan and Shun-ichi Amari},
  publisher = {Wiley},
  isbn      = {0470746661,9780470746660},
  year      = 2009
}

@article{overlap-community-detect-16,
  title   = {Overlapping Community Detection based on Network Decomposition},
  author  = {Ding, Zhuanlian and Zhang, Xingyi and Sun, Dengdi and Luo, Bin},
  journal = {Scientific Reports},
  year    = {2016},
  volume  = {6},
  number  = {1},
  pages   = {24115},
  doi     = {https://doi.org/10.1038/srep24115}
}

@book{parlet:98,
  author    = {B. N. Parlett},
  title     = {The Symmetric Eigenvalue Problem},
  publisher = {SIAM},
  address   = {Philadelphia, PA},
  year      = 1998,
  number    = 20,
  series    = {Classics in Applied Mathematics}
}

@inproceedings{pic-icml10,
  author    = {Lin, Frank and Cohen, William W.},
  title     = {Power Iteration Clustering},
  booktitle = {Proceedings of the 27th International Conference on International Conference on Machine Learning},
  series    = {ICML'10},
  year      = {2010},
  isbn      = {978-1-60558-907-7},
  location  = {Haifa, Israel},
  pages     = {655--662},
  numpages  = {8},
  url       = {http://dl.acm.org/citation.cfm?id=3104322.3104406},
  acmid     = {3104406},
  abstract  = {We present a simple and scalable graph clustering method called power iteration clustering (PIC). PIC finds a very low-dimensional embedding of a dataset using truncated power iteration on a normalized pair-wise similarity matrix of the data. This embedding turns out to be an effective cluster indicator, consistently outperforming widely used spectral methods such as NCut on real datasets. PIC is very fast on large datasets, running over 1,000 times faster than an NCut implementation based on the state-of-the-art IRAM eigenvector computation technique.}
}

@article{proj-pursuit85,
  author  = {Huber, P. J.},
  journal = {The annals of Statistics},
  number  = 2,
  pages   = {435--475},
  title   = {Projection pursuit},
  volume  = 13,
  year    = 1985
} 

@article{RPCA-graph-16,
  author  = {N. Shahid and N. Perraudin and V. Kalofolias and G. Puy and P. Vandergheynst},
  title   = {Fast Robust PCA on Graphs},
  journal = {IEEE Journal of Selected Topics in Signal Processing},
  volume  = 10,
  number  = 4,
  pages   = {740-756},
  year    = 2016
}
@inproceedings{self-tune-spectral-cluster-05,
  title     = {Self-Tuning Spectral Clustering},
  author    = {Zelnik-Manor, Lihi and Perona, Pietro},
  year      = 2005,
  booktitle = {Advances in Neural Information Processing Systems 17 (NIPS 2004)},
  editor    = {L. K. Saul and Y. Weiss and L. Bottou},
  pubisher  = {MIT Press},
  pages     = {1601-1608}
}

@article{Shi-Malik-maxcut-00,
  author  = {Shi, J. and Malik, J.},
  journal = {IEEE Transactions on Pattern Analysis and Machine
                  Intelligence},
  number  = 8,
  pages   = {888--905},
  title   = {Normalized cuts and image segmentation},
  volume  = 22,
  year    = 2000,
  doi     = {10.1109/34.868688}
}

@inproceedings{Meila01arandom,
  title = 	 {A Random Walks View of Spectral Segmentation},
  author =       {Meil\u{a}, Marina and Shi, Jianbo},
  booktitle = 	 {Proceedings of the Eighth International Workshop on Artificial Intelligence and Statistics},
  pages = 	 {203-208},
  year = 	 {2001},
  volume = 	 {R3},
  series = 	 {Proceedings of Machine Learning Research},
  month = 	 {04--07 Jan},
  publisher =    {PMLR},
  pdf = 	 {http://proceedings.mlr.press/r3/meila01a/meila01a.pdf},
  url = 	 {http://proceedings.mlr.press/r3/meila01a.html}
}

@article{Di13efficientestimation,
 author    = {Edoardo Di Napoli and Eric Polizzi and Yousef Saad},
  title     = {Efficient estimation of eigenvalue counts in an interval},
  journal   = {CoRR},
  volume    = {abs/1308.4275},
  year      = {2013},
  url       = {http://arxiv.org/abs/1308.4275},
  archivePrefix = {arXiv},
  eprint    = {1308.4275},
  timestamp = {Mon, 13 Aug 2018 16:48:46 +0200}
}
@article{Shuman-SP-graph-13,
  title   = {The emerging field of signal processing on graphs: {Extending} high-dimensional data
                  analysis to networks and other irregular domains},
  author  = {Shuman, D. I. and Narang, S. K. and Frossard, P. and Ortega, A. and Vandergheynst, P.},
  volume  = 30,
  number  = 3,
  journal = {IEEE Signal Processing Magazine},
  year    = 2013,
  pages   = {83--98},
  url     = {http://dx.doi.org/10.1109/MSP.2012.2235192}
}

@inproceedings{small-community15,
  author    = {Li, Yixuan and He, Kun and Bindel, David and Hopcroft, John E.},
  title     = {Uncovering the Small Community Structure in Large Networks: A Local Spectral Approach},
  booktitle = {Proceedings of the 24th International Conference on World Wide Web},
  series    = {WWW '15},
  year      = {2015},
  pages     = {658--668},
  publisher = {ACM}
}

@article{sPCA-asp,
  author   = {A. d'Aspremont and L. E. Ghaoui and
                  M. I. Jordan and G. R. G. Lanckriet},
  title    = {A Direct Formulation for Sparse {PCA} Using
                  Semidefinite Programming},
  year     = 2007,
  journal  = {SIAM Review},
  volume   = 49,
  number   = 3,
  pages    = {434-448},
  keywords = {principal component analysis; KarhunenLo\`{e}ve
                  transform; factor analysis; semidefinite relaxation;
                  MoreauYosida regularization; semidefinite
                  programming}
}

@article{sPCA-lowrank-08,
  author  = {H. Shen and J. Huang},
  title   = {Sparse principal component analysis via regularized
                  low rank matrix approximation},
  journal = {Journal of Multivariate Analysis},
  volume  = 99,
  number  = 6,
  year    = 2008
}

@article{sPCA-zou,
  author  = {Zou, H. and Hastie, T. and Tibshirani, R.},
  title   = {Sparse principal component analysis},
  journal = {Journal of Computational and Graphical Statistics},
  year    = 2006,
  volume  = 15,
  pages   = {265-286}
}
@article{spec-learn-10,
  title    = {On Spectral Learning},
  author   = {Argyriou, A. and Micchelli, C. A. and Massimiliano, P.},
  journal  = {Journal of Machine Learning Research},
  pages    = {935--953},
  volume   = 11,
  year     = 2010,
  keywords = {kernel methods,matrix learning,minimal norm
                  interpolation,multi-task learning,orthogonally
                  invariant norms,regularization}
}
@article{spec-orth97,
  author   = {V. Spiridonov and L. Vinet and A. Zhedanov},
  title    = {Spectral transformations, self-similar reductions and orthogonal polynomials},
  journal  = {Journal of Physics A: Mathematical and General},
  volume   = {30},
  number   = {21},
  pages    = {7621-7637},
  year     = {1997},
  abstract = {We study spectral transformations in the theory of orthogonal polynomials which are similar to Darboux transformations for the Schrodinger equation. Linear transformations of the Stieltjes function with coefficients that are rational in the argument are constructed as iterations of the Christoffel and Geronimus transformations. We describe a characteristic property of semi-classical orthogonal polynomials (SCOP) on the uniform and the exponential lattice; namely, that all these polynomials can be obtained through simple quasi-periodic and q-periodic (self-similar) closures of the chain of linear spectral transformations. In the self-similar setting, a characterization of the Laguerre - Hahn polynomials on linear and q-linear lattices is obtained by considering rational transformations of the Stieltjes function generated by transitions to the associated polynomials.}
}

@article{spect-regu-10,
  author  = {Mazumder, Rahul and Hastie, Trevor and Tibshirani,
                  Robert},
  title   = {Spectral Regularization Algorithms for Learning
                  Large Incomplete Matrices},
  journal = JMLR,
  volume  = 11,
  year    = 2010,
  pages   = {2287--2322}
}
%?  pages =	 {849--856},

@book{spectral-cluster-graph-2013,
  title     = {Spectral Clustering and Biclustering: Learning Large Graphs and Contingency Tables},
  author    = {Marianna Bolla},
  publisher = {Wiley},
  year      = 2013
} 

@misc{spectral-GNN-20,
  title         = {Spectral Clustering with Graph Neural Networks for Graph Pooling},
  author        = {Filippo Maria Bianchi and Daniele Grattarola and Cesare Alippi},
  year          = 2020,
  eprint        = {1907.00481},
  archiveprefix = {arXiv},
  primaryclass  = {cs.LG}
}

@article{spectral-redemp-13,
  author  = {Krzakala, Florent and Moore, Cristopher and Mossel,
                  Elchanan and Neeman, Joe and Sly, Allan and
                  Zdeborov{\'a}, Lenka and Zhang, Pan},
  title   = {Spectral redemption in clustering sparse networks},
  volume  = 110,
  number  = 52,
  pages   = {20935--20940},
  year    = 2013,
  url     = {https://www.pnas.org/content/110/52/20935},
  journal = PNAS
}


@article{spectral-unmixing-14,
  author  = {Junmin Liu and Jiangshe Zhang},
  journal = {IEEE Transactions on Geoscience and Remote Sensing},
  title   = {Spectral Unmixing via Compressive Sensing},
  year    = 2014,
  volume  = 52,
  number  = 11,
  pages   = {7099-7110}
}
@inproceedings{liu-2007,
  author    = {Liu, Tie-Yan and Yang, Huai-Yuan and Zheng, Xin and Qin, Tao and Ma, Wei-Ying},
  title     = {Fast Large-Scale Spectral Clustering by Sequential Shrinkage Optimization},
  year      = {2007},
  isbn      = {9783540714941},
  publisher = {Springer-Verlag},
  address   = {Berlin, Heidelberg},
  abstract  = {In many applications, we need to cluster large-scale data objects. However, some recently proposed clustering algorithms such as spectral clustering can hardly handle large-scale applications due to the complexity issue, although their effectiveness has been demonstrated in previous work. In this paper, we propose a fast solver for spectral clustering. In contrast to traditional spectral clustering algorithms that first solve an eigenvalue decomposition problem, and then employ a clustering heuristic to obtain labels for the data points, our new approach sequentially decides the labels of relatively well-separated data points. Because the scale of the problem shrinks quickly during this process, it can be much faster than the traditional methods. Experiments on both synthetic data and a large collection of product records show that our algorithm can achieve significant improvement in speed as compared to traditional spectral clustering algorithms.},
  booktitle = {Proceedings of the 29th European Conference on IR Research},
  pages     = {319-330},
  numpages  = {12},
  location  = {Rome, Italy},
  series    = {ECIR'07}
}

@article{Fowlkes-2004,
  author  = {Fowlkes, C. and Belongie, S. and Chung, F. and Malik, J.},
  journal = {IEEE Transactions on Pattern Analysis and Machine Intelligence},
  title   = {Spectral grouping using the Nystrom method},
  year    = {2004},
  volume  = {26},
  number  = {2},
  pages   = {214-225},
  doi     = {10.1109/TPAMI.2004.1262185}
}

@inproceedings{wang-2009,
  author    = {Wang, Liang and Leckie, Christopher and Ramamohanarao, Kotagiri and Bezdek, James},
  editor    = {Theeramunkong, Thanaruk and Kijsirikul, Boonserm and Cercone, Nick and Ho, Tu-Bao},
  title     = {Approximate Spectral Clustering},
  booktitle = {Advances in Knowledge Discovery and Data Mining},
  year      = {2009},
  publisher = {Springer Berlin Heidelberg},
  address   = {Berlin, Heidelberg},
  pages     = {134--146},
  abstract  = {While spectral clustering has recently shown great promise, computational cost makes it infeasible for use with large data sets. To address this computational challenge, this paper considers the problem of approximate spectral clustering, which enables both the feasibility (of approximately clustering in very large and unloadable data sets) and acceleration (of clustering in loadable data sets), while maintaining acceptable accuracy. We examine and propose several schemes for approximate spectral grouping, and make an empirical comparison of those schemes in combination with several sampling strategies. Experimental results on several synthetic and real-world data sets show that approximate spectral clustering can achieve both the goals of feasibility and acceleration.},
  isbn      = {978-3-642-01307-2}
}


@inproceedings{sakai-2009,
  author    = {Sakai, Tomoya and Imiya, Atsushi},
  editor    = {Perner, Petra},
  title     = {Fast Spectral Clustering with Random Projection and Sampling},
  booktitle = {Machine Learning and Data Mining in Pattern Recognition},
  year      = {2009},
  publisher = {Springer Berlin Heidelberg},
  address   = {Berlin, Heidelberg},
  pages     = {372--384},
  abstract  = {This paper proposes a fast spectral clustering method for large-scale data. In the present method, random projection and random sampling techniques are adopted for reducing the data dimensionality and cardinality. The computation time of the present method is quasi-linear with respect to the data cardinality. The clustering result can be updated with a small computational cost when data samples or random samples are appended or removed.},
  isbn      = {978-3-642-03070-3}
}

@inproceedings{chen-2011,
  author    = {Chen, Xinlei and Cai, Deng},
  title     = {Large Scale Spectral Clustering with Landmark-Based Representation},
  year      = {2011},
  publisher = {AAAI Press},
  abstract  = {Spectral clustering is one of the most popular clustering approaches. Despite its good performance, it is limited in its applicability to large-scale problems due to its high computational complexity. Recently, many approaches have been proposed to accelerate the spectral clustering. Unfortunately, these methods usually sacrifice quite a lot information of the original data, thus result in a degradation of performance. In this paper, we propose a novel approach, called Landmark-based Spectral Clustering (LSC), for large scale clustering problems. Specifically, we select p (≪ n) representative data points as the landmarks and represent the original data points as the linear combinations of these landmarks. The spectral embedding of the data can then be efficiently computed with the landmark-based representation. The proposed algorithm scales linearly with the problem size. Extensive experiments show the effectiveness and efficiency of our approach comparing to the state-of-the-art methods.},
  booktitle = {Proceedings of the Twenty-Fifth AAAI Conference on Artificial Intelligence},
  pages     = {313-318},
  numpages  = {6},
  location  = {San Francisco, California},
  series    = {AAAI'11}
}

@article{dhillon-2007,
  author  = {Dhillon, Inderjit and Guan, Yuqiang and Kulis, Brian},
  year    = {2007},
  month   = {12},
  pages   = {1944-57},
  title   = {Weighted Graph Cuts without Eigenvectors A Multilevel Approach},
  volume  = {29},
  journal = {IEEE transactions on pattern analysis and machine intelligence},
  doi     = {10.1109/TPAMI.2007.1115}
}

@article{har-peled-2004,
  title   = {Coresets for \$k\$-Means and \$k\$-Median Clustering and their Applications},
  author  = {Sariel Har-Peled and S. Mazumdar},
  journal = {ArXiv},
  year    = {2004},
  volume  = {abs/1810.12826}
}

@article{filippone-2008,
  author     = {Filippone, Maurizio and Camastra, Francesco and Masulli, Francesco and Rovetta, Stefano},
  title      = {A Survey of Kernel and Spectral Methods for Clustering},
  year       = {2008},
  issue_date = {January, 2008},
  publisher  = {Elsevier Science Inc.},
  address    = {USA},
  volume     = {41},
  number     = {1},
  issn       = {0031-3203},
  url        = {https://doi.org/10.1016/j.patcog.2007.05.018},
  doi        = {10.1016/j.patcog.2007.05.018},
  abstract   = {Clustering algorithms are a useful tool to explore data structures and have been employed in many disciplines. The focus of this paper is the partitioning clustering problem with a special interest in two recent approaches: kernel and spectral methods. The aim of this paper is to present a survey of kernel and spectral clustering methods, two approaches able to produce nonlinear separating hypersurfaces between clusters. The presented kernel clustering methods are the kernel version of many classical clustering algorithms, e.g., K-means, SOM and neural gas. Spectral clustering arise from concepts in spectral graph theory and the clustering problem is configured as a graph cut problem where an appropriate objective function has to be optimized. An explicit proof of the fact that these two paradigms have the same objective is reported since it has been proven that these two seemingly different approaches have the same mathematical foundation. Besides, fuzzy kernel clustering methods are presented as extensions of kernel K-means clustering algorithm.},
  journal    = {Pattern Recogn.},
  month      = jan,
  pages      = {176-190},
  numpages   = {15},
  keywords   = {Kernel fuzzy clustering, Partitional clustering, Kernel clustering, Mercer kernels, Spectral clustering}
}
@article{decelle-2011,
  title     = {Asymptotic analysis of the stochastic block model for modular networks and its algorithmic applications},
  volume    = {84},
  issn      = {1550-2376},
  url       = {http://dx.doi.org/10.1103/PhysRevE.84.066106},
  doi       = {10.1103/physreve.84.066106},
  number    = {6},
  journal   = {Physical Review E},
  publisher = {American Physical Society (APS)},
  author    = {Decelle, Aurelien and Krzakala, Florent and Moore, Cristopher and Zdeborová, Lenka},
  year      = {2011},
  month     = {Dec}
}

@article{jain-2010,
  title    = {Data clustering: 50 years beyond K-means},
  journal  = {Pattern Recognition Letters},
  volume   = {31},
  number   = {8},
  pages    = {651-666},
  year     = {2010},
  note     = {Award winning papers from the 19th International Conference on Pattern Recognition (ICPR)},
  issn     = {0167-8655},
  doi      = {https://doi.org/10.1016/j.patrec.2009.09.011},
  url      = {https://www.sciencedirect.com/science/article/pii/S0167865509002323},
  author   = {Anil K. Jain},
  keywords = {Data clustering, User’s dilemma, Historical developments, Perspectives on clustering, King-Sun Fu prize},
  abstract = {Organizing data into sensible groupings is one of the most fundamental modes of understanding and learning. As an example, a common scheme of scientific classification puts organisms into a system of ranked taxa: domain, kingdom, phylum, class, etc. Cluster analysis is the formal study of methods and algorithms for grouping, or clustering, objects according to measured or perceived intrinsic characteristics or similarity. Cluster analysis does not use category labels that tag objects with prior identifiers, i.e., class labels. The absence of category information distinguishes data clustering (unsupervised learning) from classification or discriminant analysis (supervised learning). The aim of clustering is to find structure in data and is therefore exploratory in nature. Clustering has a long and rich history in a variety of scientific fields. One of the most popular and simple clustering algorithms, K-means, was first published in 1955. In spite of the fact that K-means was proposed over 50 years ago and thousands of clustering algorithms have been published since then, K-means is still widely used. This speaks to the difficulty in designing a general purpose clustering algorithm and the ill-posed problem of clustering. We provide a brief overview of clustering, summarize well known clustering methods, discuss the major challenges and key issues in designing clustering algorithms, and point out some of the emerging and useful research directions, including semi-supervised clustering, ensemble clustering, simultaneous feature selection during data clustering, and large scale data clustering.}
}

@book{spetral-book,
  author    = {J. P. Boyd},
  title     = {Chebyshev and Fourier Spectral Methods},
  publisher = {Dover Publications},
  year      = 2000,
  address   = {New York},
  edition   = {Second}
}
@article{spielman-07,
  title   = {{Spectral partitioning works: Planar graphs and finite element meshes}},
  author  = {Spielman, D. A. and Teng, S.-H.},
  journal = {Linear Algebra and its Applications},
  number  = {2-3},
  pages   = {284--305},
  volume  = 421,
  year    = 2007
}

@article{SRU-lei-17,
  title   = {Training RNNs as Fast as CNNs},
  author  = {Lei, Tao and Zhang, Yu},
  journal = {arXiv preprint arXiv:1709.02755},
  year    = {2017}
}

@book{stewar:01book,
  author    = {G. W. Stewart},
  year      = {2001},
  title     = {Matrix Algorithms {II}: Eigensystems},
  publisher = {SIAM},
  address   = {Philadelphia}
}


@book{stewar:98book,
  author    = {G. W. Stewart},
  year      = {1998},
  title     = {Matrix Algorithms I: Basic Decompositions},
  publisher = {SIAM},
  address   = {Philadelphia}
}

@article{stewar:99,
  author  = {G. W. Stewart},
  title   = {Four Algorithms for the The Efficient Computation of
                  Truncated Pivoted {QR} Approximations to a Sparse
                  Matrix },
  journal = {Numerische Mathematik},
  year    = 1999,
  volume  = 83,
  pages   = {313-323}
}

@book{stsu:90,
  author    = {Stewart, G. W. and Sun, J. G.},
  title     = {Matrix perturbation theory},
  publisher = {Academic Press},
  address   = {Boston, MA},
  year      = {1990}
}

@article{SVD-ALS-15,
  author  = {Trevor Hastie and Rahul Mazumder and Jason Lee and Reza Zadeh},
  title   = {Matrix Completion and Low-Rank {SVD} via Fast Alternating Least Squares},
  journal = JMLR,
  volume  = {16},
  year    = 2015,
  pages   = {3367--3402}
} 

@article{svt-10,
  author  = {Cai, J.F. and Cand\`{e}s, E.J. and Shen, Z.},
  journal = SIOPT,
  number  = 4,
  pages   = {1956--1982},
  title   = {{A singular value thresholding algorithm for matrix
                  completion}},
  volume  = 20,
  year    = 2010
}

@book{temp:eig,
  title     = {Templates for the solution of algebraic eigenvalue problems},
  editor    = {Z. Bai and J. Demmel and J. Dongarra and A. Ruhe and H. van der Vorst},
  publisher = {SIAM},
  address   = {Philadelphia, PA},
  year      = 2000
}

@book{temp:lin,
  title     = {Templates for the solution of linear systems},
  editor    = {R. Barrett and M. W. Berry and T. F. Chan and J. Demmel and J. Donato and J. Dongarra and
                  V. Eijkhout and R. Pozo and C. Romine and H. van der Vorst},
  publisher = {SIAM},
  address   = {Philadelphia, PA},
  year      = 1994
}

@misc{tremblay-compressive-SC-16,
  title        = {Compressive Spectral Clustering},
  author       = {Nicolas Tremblay and Gilles Puy and Remi Gribonval and Pierre Vandergheynst},
  year         = {arXiv:1602.02018, 2016},
  primaryclass = {cs.DS}
}

@article{tremblay-fast-graph-FT-18,
  title   = {Approximate Fast Graph {Fourier} Transforms via Multilayer Sparse Approximations},
  author  = {L. Le Magoarou and R. Gribonval and N. Tremblay},
  journal = {IEEE Transactions on Signal and Information Processing over Networks},
  year    = 2018,
  volume  = 4,
  number  = 2,
  pages   = {407--420}
}
%% editor =	 {D. D. Lee and M. Sugiyama and U. V. Luxburg and I. Guyon and R. Garnett},



@misc{tremblay-filter-design-17,
  title        = {Design of graph filters and filterbanks},
  author       = {Nicolas Tremblay and Paulo Goncalves and Pierre Borgnat},
  year         = {arXiv:1711.02046, 2017},
  primaryclass = {eess.SP}
}


@inproceedings{ussl-07,
  author    = {D. Cai and X. He and J. Han},
  title     = {Spectral Regression: A Unified Approach for Sparse
                  Subspace Learning},
  year      = 2007,
  booktitle = {ICDM 2007. Seventh IEEE International Conference on
                  Data Mining},
  pages     = {73-82},
  address   = {Omaha, NE}
}
@inproceedings{ussl-07-image,
  author    = {D. Cai and X. He and J. Han},
  title     = {Spectral regression: a unified subspace learning
                  framework for content-based image retrieval},
  booktitle = {Proceedings of the 15th international conference on
                  Multimedia},
  pages     = {403 - 412},
  year      = 2007,
  address   = {Augsburg, Germany}
}

@misc{wavelets-graph-spectral-09,
  title        = {Wavelets on Graphs via Spectral Graph Theory},
  author       = {David K Hammond and Pierre Vandergheynst and Remi Gribonval},
  year         = {arXiv:0912.3848, 2009},
  primaryclass = {math.FA}
}

@article{wolfe-09,
  author  = {Belabbas, M.-A. and Wolfe, P. J.},
  title   = {Spectral methods in machine learning and new strategies for very large datasets},
  journal = PNAS,
  volume  = 106,
  number  = 2,
  pages   = {369-374},
  year    = 2009
}

@misc{wu-GNN-survey-19,
  title        = {A Comprehensive Survey on Graph Neural Networks},
  author       = {Zonghan Wu and Shirui Pan and Fengwen Chen and Guodong Long and Chengqi Zhang and Philip S. Yu},
  year         = {arXiv:1901.00596,  2019},
  primaryclass = {cs.LG}
}
@article{xu-jordan-06,
  author  = {Xu, L. and Jordan, M. I.},
  title   = {On convergence properties of the {EM} algorithm for
                  gaussian mixtures},
  journal = {Neural Comput.},
  volume  = 8,
  number  = 1,
  year    = 1996,
  pages   = {129--151}
}
@misc{YuxinChen-GovindaKamath-16,
  title     = {Community Recovery in Graphs with Locality},
  author    = {Yuxin Chen and Govinda Kamath and Changho Suh and David Tse},
  booktitle = {Proceedings of The 33rd International Conference on Machine Learning},
  editor    = {Maria Florina Balcan and Kilian Q. Weinberger},
  year      = {2016},
  pages     = {689--698},
  publisher = {PMLR},
  url       = {http://proceedings.mlr.press/v48/chena16.html},
  abstract  = {Motivated by applications in domains such as social networks and computational biology, we study the problem of community recovery in graphs with locality. In this problem, pairwise noisy measurements of whether two nodes are in the same community or different communities come mainly or exclusively from nearby nodes rather than uniformly sampled between all node pairs, as in most existing models. We present two algorithms that run nearly linearly in the number of measurements and which achieve the information limits for exact recovery.}
}
@inproceedings{zha-ding-01,
  author    = {H. Zha and C. Ding and M. Gu and X. He and H.D. Simon},
  title     = {Spectral Relaxation for {K-means} Clustering},
  booktitle = {Neural Information Processing Systems},
  series    = {NIPS '01},
  volume    = 14,
  year      = 2001,
  location  = {Vancouver, Canada},
  pages     = {1057-1064}
}
@article{zhedanov97,
  title   = {Rational spectral transformations and orthogonal
                  polynomials},
  author  = {A. Zhedanov},
  journal = JCAM,
  volume  = 85,
  number  = 1,
  pages   = {67 - 86},
  year    = 1997
}

@inproceedings{Bottou95convergenceproperties,
  author    = {L\'eon Bottou and Yoshua Bengio},
  title     = {Convergence Properties of the K-Means Algorithms},
  booktitle = {Advances in Neural Information Processing Systems 7},
  year      = {1995},
  pages     = {585--592},
  publisher = {MIT Press}
}

@inproceedings{zhang-96-birch,
  author    = {Zhang, Tian and Ramakrishnan, Raghu and Livny, Miron},
  title     = {BIRCH: An Efficient Data Clustering Method for Very Large Databases},
  year      = {1996},
  isbn      = {0897917944},
  publisher = {Association for Computing Machinery},
  address   = {New York, NY, USA},
  url       = {https://doi.org/10.1145/233269.233324},
  doi       = {10.1145/233269.233324},
  abstract  = {Finding useful patterns in large datasets has attracted considerable interest recently, and one of the most widely studied problems in this area is the identification of clusters, or densely populated regions, in a multi-dimensional dataset. Prior work does not adequately address the problem of large datasets and minimization of I/O costs.This paper presents a data clustering method named BIRCH (Balanced Iterative Reducing and Clustering using Hierarchies), and demonstrates that it is especially suitable for very large databases. BIRCH incrementally and dynamically clusters incoming multi-dimensional metric data points to try to produce the best quality clustering with the available resources (i.e., available memory and time constraints). BIRCH can typically find a good clustering with a single scan of the data, and improve the quality further with a few additional scans. BIRCH is also the first clustering algorithm proposed in the database area to handle "noise" (data points that are not part of the underlying pattern) effectively.We evaluate BIRCH's time/space efficiency, data input order sensitivity, and clustering quality through several experiments. We also present a performance comparisons of BIRCH versus CLARANS, a clustering method proposed recently for large datasets, and show that BIRCH is consistently superior.},
  booktitle = {Proceedings of the 1996 ACM SIGMOD International Conference on Management of Data},
  pages     = {103-114},
  numpages  = {12},
  location  = {Montreal, Quebec, Canada},
  series    = {SIGMOD '96}
}

@inproceedings{Macqueen67kmeans,
  author    = {J. Macqueen},
  title     = {Some methods for classification and analysis of multivariate observations},
  booktitle = {In 5-th Berkeley Symposium on Mathematical Statistics and Probability},
  year      = {1967},
  pages     = {281-297}
}

@article{Lloyd-82-kmeans,
  author  = {Lloyd, S.},
  journal = {IEEE Transactions on Information Theory},
  title   = {Least squares quantization in PCM},
  year    = {1982},
  volume  = {28},
  number  = {2},
  pages   = {129-137},
  doi     = {10.1109/TIT.1982.1056489}
}

@article{Cheng95meanshift,
  author  = {Yizong Cheng},
  journal = {IEEE Transactions on Pattern Analysis and Machine Intelligence},
  title   = {Mean shift, mode seeking, and clustering},
  year    = {1995},
  volume  = {17},
  number  = {8},
  pages   = {790-799},
  doi     = {10.1109/34.400568}
}

@inproceedings{Ester96adensity-based,
  author    = {Martin Ester and Hans-Peter Kriegel and J\"org Sander and Xiaowei Xu},
  title     = {A density-based algorithm for discovering clusters in large spatial databases with noise},
  booktitle = {},
  year      = {1996},
  pages     = {226-231},
  publisher = {AAAI Press}
}

@inbook{Ding05-nnmf-spectral,
  author    = {Ding,Chris and He,Xiaofeng and Simon,Horst D.},
  year      = {2005},
  month     = {April 21,},
  title     = {On the Equivalence of Nonnegative Matrix Factorization and Spectral Clustering},
  series    = {Proceedings of the 2005 SIAM International Conference on Data Mining (SDM)},
  publisher = {Society for Industrial and Applied Mathematics},
  pages     = {606-610},
  isbn      = {9780898715934},
  url       = {https://epubs.siam.org/doi/abs/10.1137/1.9781611972757.70}
}

@article{Lawton-1971-nnmf,
  author    = { William H.   Lawton  and  Edward A.   Sylvestre },
  title     = {Self Modeling Curve Resolution},
  journal   = {Technometrics},
  volume    = {13},
  number    = {3},
  pages     = {617-633},
  year      = {1971},
  publisher = {Taylor & Francis},
  doi       = {10.1080/00401706.1971.10488823},
  url       = {https://www.tandfonline.com/doi/abs/10.1080/00401706.1971.10488823},
  eprint    = {https://www.tandfonline.com/doi/pdf/10.1080/00401706.1971.10488823}
}

@article{Paatero1991-nnmf,
  title   = {Matrix factorization methods for analysing diffusion battery data},
  journal = {Journal of Aerosol Science},
  volume  = {22},
  pages   = {S273-S276},
  year    = {1991},
  issn    = {0021-8502},
  doi     = {https://doi.org/10.1016/S0021-8502(05)80089-8},
  url     = {https://www.sciencedirect.com/science/article/pii/S0021850205800898},
  author  = {Pentti Paatero and Unto Tapper and Pasi Aalto and Markku Kulmala}
}

@inproceedings{Zhang-2108-pca,
  author    = {Zhang, Nian and Leatham, Keenan and Xiong, Jiang and Zhong, Jing},
  booktitle = {2018 Ninth International Conference on Intelligent Control and Information Processing (ICICIP)},
  title     = {PCA-K-Means Based Clustering Algorithm for High Dimensional and Overlapping Spectra Signals},
  year      = {2018},
  volume    = {},
  number    = {},
  pages     = {349-354},
  doi       = {10.1109/ICICIP.2018.8606667}
}

@article{mohar-1991,
  author  = {Mohar, B and Alavi, Y and Chartrand, G and Oellermann, Ortrud and Schwenk, Allen},
  year    = {1991},
  month   = {01},
  title   = {The Laplacian spectrum of graphs},
  volume  = {2},
  journal = {Graph Theory, Combinatorics and Applications},
  pages = {871-898},
  publisher = {Wiley}
}

@inbook{mohar-1997,
  author    = {Mohar, Bojan},
  title     = {Some applications of Laplace eigenvalues of graphs},
  booktitle = {Graph Symmetry: Algebraic Methods and Applications},
  year      = {1997},
  publisher = {Springer Netherlands},
  address   = {Dordrecht},
  pages     = {225-275},
  isbn      = {978-94-015-8937-6},
  doi       = {10.1007/978-94-015-8937-6_6},
  url       = {https://doi.org/10.1007/978-94-015-8937-6_6}
}

@article{hagen-kahng-1992,
  author  = {Hagen, L. and Kahng, A.B.},
  journal = {IEEE Transactions on Computer-Aided Design of Integrated Circuits and Systems},
  title   = {New spectral methods for ratio cut partitioning and clustering},
  year    = {1992},
  volume  = {11},
  number  = {9},
  doi     = {10.1109/43.159993}
}

@article{DIMLow,
    author = {I. K\"arkk\"ainen and P. Fr\"anti},
    title = {Gradual model generator for single-pass clustering},
    journal = {Pattern Recognition},
    year = {2007},
    volume = {40},
    number = {3},
    pages = {784--795}
}